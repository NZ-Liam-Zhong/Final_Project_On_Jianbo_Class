{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PGiTnKFFTNi",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# CIS6800: Project 1b: Deep Learning Basics Part B\n",
        "\n",
        "### Instructions:\n",
        "* This is an individual assignment. Collaborating with others is not permitted.\n",
        "* There is no single answer to most problems in deep learning, therefore the questions will often be underspecified. You need to fill in the blanks and submit a solution that solves the (practical) problem. Document the choices (hyperparameters, features, neural network architectures, etc.) you made where specified.\n",
        "* All the code should be written in Python. You should only use PyTorch to complete this project.\n",
        "* You are encouraged to use ChatGPT, but you need to make a summary of how you used it, and the code that you have copied from it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q41jvpsZFTNn",
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to download MNIST dataset. This may be due to SSL certificate issues or the dataset URL being unavailable.\n",
            "Troubleshooting steps:\n",
            "1. Ensure your system's SSL certificates are up to date.\n",
            "   - On macOS, run: /Applications/Python\\ 3.x/Install\\ Certificates.command\n",
            "   - On Ubuntu/Debian, run: sudo apt-get install --reinstall ca-certificates\n",
            "2. If you are behind a proxy or firewall, check your network settings.\n",
            "3. If the problem persists, manually download the MNIST files from:\n",
            "   https://ossci-datasets.s3.amazonaws.com/mnist/\n",
            "   and place them in the './MNIST/raw/' directory.\n",
            "Original error message:\n",
            "Error downloading train-images-idx3-ubyte.gz:\n",
            "Tried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\n",
            "Tried http://yann.lecun.com/exdb/mnist/, got:\n",
            "HTTP Error 404: Not Found\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error downloading train-images-idx3-ubyte.gz:\nTried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\nTried http://yann.lecun.com/exdb/mnist/, got:\nHTTP Error 404: Not Found\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Download MNIST with improved SSL handling and error messaging\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFailed to download MNIST dataset. This may be due to SSL certificate issues or the dataset URL being unavailable.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Github/cis6800hw/.venv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:100\u001b[39m, in \u001b[36mMNIST.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Github/cis6800hw/.venv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:197\u001b[39m, in \u001b[36mMNIST.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mirror, err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors, errors):\n\u001b[32m    196\u001b[39m     s += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTried \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(s)\n",
            "\u001b[31mRuntimeError\u001b[39m: Error downloading train-images-idx3-ubyte.gz:\nTried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\nTried http://yann.lecun.com/exdb/mnist/, got:\nHTTP Error 404: Not Found\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "rng_seed = 45510\n",
        "\n",
        "# Download MNIST\n",
        "torchvision.datasets.MNIST('.', download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxU8GMDlFTNo",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 4. Adversarial Images (30%)\n",
        "In this part you will see how you can use the gradients of the network to generate adversarial\n",
        "images. Using these images that look almost identical the original you will be able to fool\n",
        "different neural networks. You will also see that these images also affect different neural\n",
        "networks and expose a security issue of CNNs that malicious users can take advantage of.\n",
        "An example is shown in Figure 4. You are encouraged to read the relevant papers [1, 2]\n",
        "before solving this part.\n",
        "\n",
        "<div><img src=\"https://github.com/LukasZhornyak/CIS680_files/raw/main/HW1/images/fig4.png\"/></div>\n",
        "\n",
        "<center>Figure 4: An adversarial example demonstrated in [1].</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol1GPUaqFTNp"
      },
      "source": [
        "1. (10%) Use the trained network from question 3 to generate adversarial images with\n",
        "constraints. The constraints that you have are:\n",
        "\n",
        "  1. You are not allowed to erase parts of the image, i.e. $I_\\text{pert} \\ge I$ at each pixel location.\n",
        "  2. The perturbed image has to take valid values, i.e. $-1 \\le I_\\text{pert} \\le 1$.\n",
        "\n",
        "  The algorithm works as follows:\n",
        "  \n",
        "  1. Let $I$ be a test image of your dataset that you want to perturb that is classified correctly by the network. Let $I_\\epsilon$ be the perturbation that you should initialize\n",
        "with zeros.\n",
        "  2. Feed $I_\\text{pert} = I + I_\\epsilon$ in the network.\n",
        "  3. Calculate the loss given the ground truth label ($y_\\mathrm{gt}$). Let the loss be $L(x,y |\\theta)$ where $\\theta$ are the learned weights.\n",
        "  4. Compute the gradients with respect to $I_\\text{pert}$, i.e., $\\nabla_{I_\\text{pert}} L(I_\\text{pert}, y_\\mathrm{gt} | \\theta)$. Using backpropagation, compute $\\nabla_{I_\\epsilon} L(I_\\epsilon,y_\\mathrm{gt} | \\theta)$, i.e. the gradients with respect to the perturbation.\n",
        "  5. Use the Fast Gradient Sign method to update the perturbation, i.e., $I_\\epsilon = I_\\epsilon + \\epsilon\\,\\text{sign}(\\nabla_{I_\\epsilon} L(I_\\epsilon, y_\\mathrm{gt}))$, where $\\epsilon$ is a small constant of your choice.\n",
        "  6. Repeat A-D until the network classify the input image $I_\\text{pert}$ as an arbitrary\n",
        "wrong category with confidence (probability) at least $90\\%$.\n",
        "\n",
        "  Generate 2 examples of adversarial images. Describe the difference between the adversarial images and the original images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4oRChtNFTNp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Create your network here (do not change this name)\n",
        "class DigitClassification(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 3 * 3, 64)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.bn_fc1(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load trained weights\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # (-1, 1)\n",
        "])\n",
        "\n",
        "import os\n",
        "\n",
        "# Resolve model path whether notebook runs from repo root or hw1b/\n",
        "candidates = [\n",
        "    'model.pth',\n",
        "    os.path.join(os.path.dirname(os.getcwd()), 'model.pth'),  # ../model.pth\n",
        "    os.path.join(os.getcwd(), 'model.pth'),                   # cwd/model.pth\n",
        "]\n",
        "model_path = next((p for p in candidates if os.path.exists(p)), None)\n",
        "if model_path is None:\n",
        "    raise FileNotFoundError('Could not find model.pth. Expected at repo root. Please place model.pth in /Users/kyle/Github/cis6800hw/.')\n",
        "\n",
        "model = DigitClassification().to(device)\n",
        "state = torch.load(model_path, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "# Test dataset and a helper to denormalize for display\n",
        "test_ds = torchvision.datasets.MNIST('.', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "def to_img(x):\n",
        "    # map from (-1,1) to (0,1)\n",
        "    return (x.clamp(-1, 1) + 1.0) / 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpN5t009FTNq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# don't change the signature of this function (image, image_pert -> [N, 1, H, W])\n",
        "@torch.enable_grad()\n",
        "def arbitrary_adversary(model, image, original_label, eps=0.01, max_steps=200):\n",
        "    # image is normalized to (-1,1). Clone for perturbation and require grad\n",
        "    model.eval()\n",
        "    image = image.to(device)\n",
        "    label = torch.tensor([original_label], device=device)\n",
        "    image_pert = image.clone().detach().requires_grad_(True)\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    for _ in range(max_steps):\n",
        "        image_pert.grad = None\n",
        "        logits = model(image_pert)\n",
        "        probs = softmax(logits)\n",
        "        # Want any wrong class >= 0.9; we ascend loss to hurt the true class\n",
        "        loss = ce(logits, label)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            # Check if gradient exists before using it\n",
        "            if image_pert.grad is not None:\n",
        "                # FGSM update: increase loss, but enforce constraints\n",
        "                grad_sign = image_pert.grad.sign()\n",
        "                image_pert += eps * grad_sign\n",
        "                # Constraint 1: no erasing: I_pert >= I\n",
        "                image_pert = torch.maximum(image_pert, image)\n",
        "                # Constraint 2: keep in [-1, 1]\n",
        "                image_pert.clamp_(-1.0, 1.0)\n",
        "        # Check if any non-true class has prob >= 0.9\n",
        "        with torch.no_grad():\n",
        "            p = probs.squeeze(0)\n",
        "            top_prob, top_idx = torch.topk(p, 2)\n",
        "            # if top-1 is not the original class and prob>=0.9, stop\n",
        "            pred = torch.argmax(p).item()\n",
        "            if pred != int(original_label) and p[pred].item() >= 0.9:\n",
        "                break\n",
        "    return image_pert.detach()\n",
        "\n",
        "# Display images\n",
        "# pick a correctly classified sample\n",
        "model.eval()\n",
        "for img, y in test_loader:\n",
        "    img = img.to(device)\n",
        "    with torch.no_grad():\n",
        "        pred = model(img).argmax(dim=1).item()\n",
        "    if pred == int(y.item()):\n",
        "        adv = arbitrary_adversary(model, img, original_label=pred)\n",
        "        with torch.no_grad():\n",
        "            pred_adv = model(adv).argmax(dim=1).item()\n",
        "        fig, axes = plt.subplots(1,3, figsize=(9,3))\n",
        "        axes[0].imshow(to_img(img[0]).cpu().squeeze(), cmap='gray'); axes[0].set_title(f'orig: {pred}')\n",
        "        axes[1].imshow(to_img(adv[0]).cpu().squeeze(), cmap='gray'); axes[1].set_title(f'adv: {pred_adv}')\n",
        "        axes[2].imshow((to_img(adv[0]) - to_img(img[0])).cpu().squeeze(), cmap='bwr'); axes[2].set_title('delta')\n",
        "        for ax in axes: ax.axis('off')\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgJIt0UjFTNr"
      },
      "source": [
        "2. (10%) For a test image from the dataset, choose a target label yt that you want the network to classify your image as and compute a perturbed image. Note that this is different from what you are asked in part 1, because you want your network to believe that the image has a particular label, not just misclassify the image. You need to modify appropriately the loss function and then perform gradient descent as before. You should still use the constraints from part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnHjmnq1FTNr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# don't change the signature of this function (image, image_pert -> [N, 1, H, W])\n",
        "@torch.enable_grad()\n",
        "def targeted_adversary(model, image, target_label, eps=0.01, max_steps=300):\n",
        "    # We want the model to predict target_label with high probability\n",
        "    model.eval()\n",
        "    image = image.to(device)\n",
        "    target = torch.tensor([target_label], device=device)\n",
        "    image_pert = image.clone().detach().requires_grad_(True)\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    for _ in range(max_steps):\n",
        "        image_pert.grad = None\n",
        "        logits = model(image_pert)\n",
        "        probs = softmax(logits)\n",
        "        # Minimize CE to the target class (targeted attack)\n",
        "        loss = ce(logits, target)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            # Check if gradient exists before using it\n",
        "            if image_pert.grad is not None:\n",
        "                grad_sign = image_pert.grad.sign()\n",
        "                # For targeted attack, move opposite to gradient ascent on target loss → gradient descent\n",
        "                image_pert -= eps * grad_sign\n",
        "                # Constraint: I_pert >= I (no erasing) and clamp into [-1,1]\n",
        "                image_pert = torch.maximum(image_pert, image)\n",
        "                image_pert.clamp_(-1.0, 1.0)\n",
        "        with torch.no_grad():\n",
        "            p = probs.squeeze(0)\n",
        "            pred = torch.argmax(p).item()\n",
        "            if pred == int(target_label) and p[pred].item() >= 0.9:\n",
        "                break\n",
        "    return image_pert.detach()\n",
        "\n",
        "# Display images\n",
        "# pick a sample and set a target different than its original class\n",
        "model.eval()\n",
        "for img, y in test_loader:\n",
        "    img = img.to(device)\n",
        "    orig = y.item()\n",
        "    target = (orig + 1) % 10\n",
        "    adv_t = targeted_adversary(model, img, target_label=target)\n",
        "    with torch.no_grad():\n",
        "        pred_orig = model(img).argmax(dim=1).item()\n",
        "        pred_t = model(adv_t).argmax(dim=1).item()\n",
        "    fig, axes = plt.subplots(1,3, figsize=(9,3))\n",
        "    axes[0].imshow(to_img(img[0]).cpu().squeeze(), cmap='gray'); axes[0].set_title(f'orig: {pred_orig}')\n",
        "    axes[1].imshow(to_img(adv_t[0]).cpu().squeeze(), cmap='gray'); axes[1].set_title(f'targeted→{target}: {pred_t}')\n",
        "    axes[2].imshow((to_img(adv_t[0]) - to_img(img[0])).cpu().squeeze(), cmap='bwr'); axes[2].set_title('delta')\n",
        "    for ax in axes: ax.axis('off')\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIW1jhNhFTNs"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "3. (10%) Retrain the network from the previous problem. Use some of the adversarial images you generated in parts (1) and (2) and feed them in the retrained network. What do you observe?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNx3E3qXFTNs"
      },
      "source": [
        "Clean and adversarial robustness (observed):\n",
        "- Accuracy decreases smoothly with ε for both FGSM and PGD (no obvious gradient masking). On our subset, accuracy remains high at small ε (≈0.990 at ε=0.00; ≈0.988–0.985 at ε=0.01–0.02) and is ≈0.960–0.962 at ε=0.05.\n",
        "- PGD is consistently equal or slightly stronger than FGSM (e.g., ε=0.05: FGSM ≈0.962, PGD ≈0.960), which is expected.\n",
        "- Targeted PGD (multi‑start) achieves very low attack success rates in this ε range: ≈0.01% at ε≤0.02, ≈0.1% at ε=0.03, ≈0.4% at ε=0.05.\n",
        "\n",
        "Effect of short adversarial fine‑tuning:\n",
        "- Any robustness change is marginal; curves before/after remain very close, with only small advantages at low ε. Clean accuracy stays ≥99%.\n",
        "\n",
        "If we aimed for stronger robustness gains:\n",
        "- Match train/eval with PGD and fine‑tune longer (1–3 passes) using mixed clean+adv batches (e.g., 50/50).\n",
        "- Evaluate on more samples with stronger PGD (more steps, multiple random starts) and an ε sweep; expect clearer gains at small/mid ε if FT is extended.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbzhroq4FTNt",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# (Optional) Simple adversarial fine-tuning demo (keep short to avoid long runs)\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Take a tiny subset of adversarial examples constructed on-the-fly\n",
        "optimizer_ft = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "count = 0\n",
        "adv_batch = []\n",
        "label_batch = []\n",
        "\n",
        "# Collect adversarial examples in batches to avoid batch norm issues\n",
        "for img, y in test_loader:\n",
        "    img = img.to(device)\n",
        "    y = y.to(device)\n",
        "    model.eval()  # Set to eval mode for adversarial generation\n",
        "    with torch.no_grad():\n",
        "        pred = model(img).argmax(dim=1)\n",
        "    # build either arbitrary or targeted adversarial example\n",
        "    if pred.item() == y.item():\n",
        "        adv_img = arbitrary_adversary(model, img, original_label=pred.item())\n",
        "    else:\n",
        "        adv_img = targeted_adversary(model, img, target_label=int((y.item()+1)%10))\n",
        "    \n",
        "    adv_batch.append(adv_img)\n",
        "    label_batch.append(y)\n",
        "    count += 1\n",
        "    \n",
        "    # Process in mini-batches to avoid batch norm issues with single samples\n",
        "    if len(adv_batch) >= 8 or count >= 64:\n",
        "        model.train()  # Switch to train mode for gradient update\n",
        "        batch_adv = torch.cat(adv_batch, dim=0)\n",
        "        batch_labels = torch.cat(label_batch, dim=0)\n",
        "        logits = model(batch_adv)\n",
        "        loss = nn.CrossEntropyLoss()(logits, batch_labels)\n",
        "        optimizer_ft.zero_grad(); loss.backward(); optimizer_ft.step()\n",
        "        adv_batch = []\n",
        "        label_batch = []\n",
        "        \n",
        "    if count >= 64:\n",
        "        break\n",
        "\n",
        "# Process any remaining samples\n",
        "if adv_batch:\n",
        "    model.train()\n",
        "    batch_adv = torch.cat(adv_batch, dim=0)\n",
        "    batch_labels = torch.cat(label_batch, dim=0)\n",
        "    logits = model(batch_adv)\n",
        "    loss = nn.CrossEntropyLoss()(logits, batch_labels)\n",
        "    optimizer_ft.zero_grad(); loss.backward(); optimizer_ft.step()\n",
        "\n",
        "model.eval()  # Set back to eval mode\n",
        "print('Adversarial fine-tuning steps:', count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantitative view: clean vs adversarial accuracy before/after adversarial fine-tuning\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Small eval subset to keep runtime short\n",
        "subset_loader = DataLoader(Subset(test_ds, list(range(256))), batch_size=64, shuffle=False)\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy_clean(m, loader):\n",
        "    m.eval()\n",
        "    tot, ok = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        ok += (m(x).argmax(1) == y).sum().item()\n",
        "        tot += y.size(0)\n",
        "    return ok / max(1, tot)\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy_adv(m, loader, eps=0.02, max_steps=30):\n",
        "    m.eval()\n",
        "    tot, ok = 0, 0\n",
        "    for x, y in loader:\n",
        "        for i in range(x.size(0)):\n",
        "            xi = x[i:i+1].to(device)\n",
        "            yi = int(y[i].item())\n",
        "            adv = arbitrary_adversary(m, xi, original_label=yi, eps=eps, max_steps=max_steps)\n",
        "            pred = m(adv).argmax(1).item()\n",
        "            ok += int(pred == yi)\n",
        "            tot += 1\n",
        "    return ok / max(1, tot)\n",
        "\n",
        "# Snapshot current weights\n",
        "before_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "# Metrics before fine-tuning\n",
        "acc_clean_before = accuracy_clean(model, subset_loader)\n",
        "acc_adv_before = accuracy_adv(model, subset_loader, eps=0.02, max_steps=30)\n",
        "\n",
        "# Short adversarial fine-tuning inside this cell\n",
        "optimizer_ft = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "model.train()\n",
        "steps = 0\n",
        "for x, y in subset_loader:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    for i in range(x.size(0)):\n",
        "        xi = x[i:i+1]\n",
        "        yi = y[i:i+1]\n",
        "        with torch.no_grad():\n",
        "            pred = model(xi).argmax(dim=1)\n",
        "        if pred.item() == yi.item():\n",
        "            adv_x = arbitrary_adversary(model, xi, original_label=pred.item(), eps=0.02, max_steps=30)\n",
        "        else:\n",
        "            adv_x = targeted_adversary(model, xi, target_label=int((yi.item()+1)%10), eps=0.02, max_steps=30)\n",
        "        logits = model(adv_x)\n",
        "        loss = nn.CrossEntropyLoss()(logits, yi)\n",
        "        optimizer_ft.zero_grad(); loss.backward(); optimizer_ft.step()\n",
        "        steps += 1\n",
        "        if steps >= 128:\n",
        "            break\n",
        "    if steps >= 128:\n",
        "        break\n",
        "\n",
        "# Metrics after fine-tuning\n",
        "acc_clean_after = accuracy_clean(model, subset_loader)\n",
        "acc_adv_after = accuracy_adv(model, subset_loader, eps=0.02, max_steps=30)\n",
        "\n",
        "print(f\"Before FT → clean: {acc_clean_before:.4f}, adv: {acc_adv_before:.4f}\")\n",
        "print(f\"After  FT → clean: {acc_clean_after:.4f}, adv: {acc_adv_after:.4f}\")\n",
        "\n",
        "# Plot bar chart\n",
        "labels = ['Clean', 'Adversarial']\n",
        "before = [acc_clean_before, acc_adv_before]\n",
        "after = [acc_clean_after, acc_adv_after]\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "x = [0, 1]; width = 0.35\n",
        "plt.bar([i - width/2 for i in x], before, width=width, label='Before FT')\n",
        "plt.bar([i + width/2 for i in x], after, width=width, label='After FT')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Clean vs Adversarial Accuracy (Before/After Adversarial Fine-Tuning)')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Restore original weights so other cells remain comparable\n",
        "model.load_state_dict(before_state, strict=True)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BN-safe evaluation and adversarial fine-tuning (batched)\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Small eval subset\n",
        "subset_loader = DataLoader(Subset(test_ds, list(range(256))), batch_size=64, shuffle=False)\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy_clean(m, loader):\n",
        "    m.eval()\n",
        "    tot, ok = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        ok += (m(x).argmax(1) == y).sum().item()\n",
        "        tot += y.size(0)\n",
        "    return ok / max(1, tot)\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy_adv(m, loader, eps=0.02, max_steps=30):\n",
        "    m.eval()\n",
        "    tot, ok = 0, 0\n",
        "    for x, y in loader:\n",
        "        # build adversarial batch, but keep model in eval for BN stability\n",
        "        adv_list = []\n",
        "        for i in range(x.size(0)):\n",
        "            xi = x[i:i+1].to(device)\n",
        "            yi = int(y[i].item())\n",
        "            adv = arbitrary_adversary(m, xi, original_label=yi, eps=eps, max_steps=max_steps)\n",
        "            adv_list.append(adv)\n",
        "        adv_x = torch.cat(adv_list, dim=0)\n",
        "        pred = m(adv_x).argmax(1)\n",
        "        ok += (pred.cpu() == y).sum().item()\n",
        "        tot += y.size(0)\n",
        "    return ok / max(1, tot)\n",
        "\n",
        "# Snapshot weights\n",
        "before_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "# Metrics before FT\n",
        "acc_clean_before = accuracy_clean(model, subset_loader)\n",
        "acc_adv_before = accuracy_adv(model, subset_loader, eps=0.02, max_steps=30)\n",
        "\n",
        "# Short adversarial fine-tuning: create batched adversarial examples and train with batch to satisfy BN\n",
        "optimizer_ft = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "steps = 0\n",
        "for x, y in subset_loader:\n",
        "    # Create adversarial batch in eval mode\n",
        "    model.eval()\n",
        "    adv_list = []\n",
        "    for i in range(x.size(0)):\n",
        "        xi = x[i:i+1].to(device)\n",
        "        yi_int = int(y[i].item())\n",
        "        with torch.no_grad():\n",
        "            pred = model(xi).argmax(1).item()\n",
        "        if pred == yi_int:\n",
        "            adv = arbitrary_adversary(model, xi, original_label=pred, eps=0.02, max_steps=30)\n",
        "        else:\n",
        "            adv = targeted_adversary(model, xi, target_label=(yi_int+1)%10, eps=0.02, max_steps=30)\n",
        "        adv_list.append(adv)\n",
        "    adv_x = torch.cat(adv_list, dim=0)\n",
        "    # One training step with batch (BN-safe)\n",
        "    model.train()\n",
        "    logits = model(adv_x)\n",
        "    loss = nn.CrossEntropyLoss()(logits, y.to(device))\n",
        "    optimizer_ft.zero_grad(); loss.backward(); optimizer_ft.step()\n",
        "    steps += x.size(0)\n",
        "    if steps >= 128:\n",
        "        break\n",
        "\n",
        "# Metrics after FT\n",
        "acc_clean_after = accuracy_clean(model, subset_loader)\n",
        "acc_adv_after = accuracy_adv(model, subset_loader, eps=0.02, max_steps=30)\n",
        "\n",
        "print(f\"Before FT → clean: {acc_clean_before:.4f}, adv: {acc_adv_before:.4f}\")\n",
        "print(f\"After  FT → clean: {acc_clean_after:.4f}, adv: {acc_adv_after:.4f}\")\n",
        "\n",
        "# Plot bar chart\n",
        "labels = ['Clean', 'Adversarial']\n",
        "before = [acc_clean_before, acc_adv_before]\n",
        "after = [acc_clean_after, acc_adv_after]\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "x = [0, 1]; width = 0.35\n",
        "plt.bar([i - width/2 for i in x], before, width=width, label='Before FT')\n",
        "plt.bar([i + width/2 for i in x], after, width=width, label='After FT')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Clean vs Adversarial Accuracy (Before/After Adversarial Fine-Tuning)')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Restore weights for reproducibility in later cells\n",
        "model.load_state_dict(before_state, strict=True)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PGD ε-sweep: robust accuracy before/after adversarial fine-tuning\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Small eval subset for speed\n",
        "subset_loader = DataLoader(Subset(test_ds, list(range(512))), batch_size=64, shuffle=False)\n",
        "\n",
        "ce = nn.CrossEntropyLoss()\n",
        "\n",
        "@torch.no_grad()\n",
        "def clean_acc(m, loader):\n",
        "    m.eval(); tot=0; ok=0\n",
        "    for x,y in loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        ok += (m(x).argmax(1)==y).sum().item(); tot += y.size(0)\n",
        "    return ok/max(1,tot)\n",
        "\n",
        "# Standard Linf-PGD attack (no I_pert >= I constraint) for robust curve clarity\n",
        "# Projects onto Linf ball of radius eps around the original input.\n",
        "def pgd_linf(m, x, y, eps=0.03, alpha=0.01, steps=20):\n",
        "    m.eval()\n",
        "    x0 = x.to(device)\n",
        "    y  = y.to(device)\n",
        "    # random start within Linf ball\n",
        "    x_adv = (x0 + torch.empty_like(x0).uniform_(-eps, eps)).clamp(-1,1)\n",
        "    for _ in range(steps):\n",
        "        x_adv.requires_grad_(True)\n",
        "        logits = m(x_adv)\n",
        "        loss = ce(logits, y)\n",
        "        grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "        with torch.no_grad():\n",
        "            x_adv = x_adv + alpha * grad.sign()\n",
        "            x_adv = torch.min(torch.max(x_adv, x0 - eps), x0 + eps)\n",
        "            x_adv.clamp_(-1, 1)\n",
        "    return x_adv.detach()\n",
        "\n",
        "def robust_acc_pgd(m, loader, eps, alpha=0.01, steps=20):\n",
        "    m.eval(); tot=0; ok=0\n",
        "    for x,y in loader:\n",
        "        x_adv = pgd_linf(m, x, y, eps=eps, alpha=alpha, steps=steps)\n",
        "        with torch.no_grad():\n",
        "            pred = m(x_adv).argmax(1)\n",
        "            ok += (pred.cpu()==y).sum().item(); tot += y.size(0)\n",
        "    return ok/max(1,tot)\n",
        "\n",
        "# Snapshot weights\n",
        "before_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "# Compute curves before FT\n",
        "eps_list = [0.0, 0.01, 0.02, 0.03, 0.05]\n",
        "before_curve = [ (clean_acc(model, subset_loader) if e==0.0 else robust_acc_pgd(model, subset_loader, eps=e, alpha=0.01, steps=20)) for e in eps_list ]\n",
        "\n",
        "# Short PGD-based adversarial fine-tuning with 50/50 clean+adv\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "model.train()\n",
        "steps_done = 0\n",
        "for x,y in subset_loader:\n",
        "    x,y = x.to(device), y.to(device)\n",
        "    x_adv = pgd_linf(model, x, y, eps=0.02, alpha=0.01, steps=10)\n",
        "    logits_clean = model(x)\n",
        "    logits_adv   = model(x_adv)\n",
        "    loss = 0.5*ce(logits_clean, y) + 0.5*ce(logits_adv, y)\n",
        "    optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "    steps_done += 1\n",
        "    if steps_done >= 8:\n",
        "        break\n",
        "\n",
        "# Compute curves after FT\n",
        "after_curve = [ (clean_acc(model, subset_loader) if e==0.0 else robust_acc_pgd(model, subset_loader, eps=e, alpha=0.01, steps=20)) for e in eps_list ]\n",
        "\n",
        "print('ε values:', eps_list)\n",
        "print('Before:', [f\"{v:.4f}\" for v in before_curve])\n",
        "print('After :', [f\"{v:.4f}\" for v in after_curve])\n",
        "\n",
        "# Plot curves\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(eps_list, before_curve, marker='o', label='Before FT')\n",
        "plt.plot(eps_list, after_curve, marker='o', label='After FT')\n",
        "plt.xlabel('ε (L∞)'); plt.ylabel('Accuracy'); plt.ylim(0,1.0)\n",
        "plt.title('Robust Accuracy vs ε (PGD, 20 steps)')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Restore weights\n",
        "model.load_state_dict(before_state, strict=True)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# robustness test on adverserial images, on more adverserial images that\n",
        "# we generate. and just overall robustness test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5KpnmwiFTNu"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## References\n",
        "<div><img src=\"https://github.com/LukasZhornyak/CIS680_files/raw/main/HW1/images/refs.png\"/, width=600\n",
        "         ></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Robustness evaluation suite: FGSM/PGD curves and targeted attack success rate (ASR)\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Build evaluation subset\n",
        "N_EVAL = 2000  # adjust higher for tighter CIs\n",
        "subset_loader = DataLoader(Subset(test_ds, list(range(min(N_EVAL, len(test_ds))))), batch_size=128, shuffle=False)\n",
        "\n",
        "ce = nn.CrossEntropyLoss()\n",
        "\n",
        "@torch.no_grad()\n",
        "def acc_clean(m, loader):\n",
        "    m.eval(); tot=0; ok=0\n",
        "    for x,y in loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        ok += (m(x).argmax(1)==y).sum().item(); tot += y.size(0)\n",
        "    return ok/max(1,tot)\n",
        "\n",
        "# FGSM untargeted (uses sign of grad of CE wrt true label)\n",
        "def fgsm(m, x, y, eps):\n",
        "    m.eval()\n",
        "    x = x.to(device).detach().requires_grad_(True)\n",
        "    y = y.to(device)\n",
        "    logits = m(x)\n",
        "    loss = ce(logits, y)\n",
        "    m.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        x_adv = (x + eps * x.grad.sign()).clamp(-1,1)\n",
        "    return x_adv.detach()\n",
        "\n",
        "# PGD untargeted (standard Linf ball)\n",
        "def pgd(m, x, y, eps=0.03, alpha=0.01, steps=20, rs=True):\n",
        "    m.eval()\n",
        "    x0 = x.to(device)\n",
        "    y  = y.to(device)\n",
        "    if rs:\n",
        "        x_adv = (x0 + torch.empty_like(x0).uniform_(-eps, eps)).clamp(-1,1)\n",
        "    else:\n",
        "        x_adv = x0.clone()\n",
        "    for _ in range(steps):\n",
        "        x_adv.requires_grad_(True)\n",
        "        logits = m(x_adv)\n",
        "        loss = ce(logits, y)\n",
        "        grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "        with torch.no_grad():\n",
        "            x_adv = x_adv + alpha * grad.sign()\n",
        "            x_adv = torch.min(torch.max(x_adv, x0 - eps), x0 + eps)\n",
        "            x_adv.clamp_(-1, 1)\n",
        "    return x_adv.detach()\n",
        "\n",
        "def acc_under_attack(m, loader, method='fgsm', eps=0.02, steps=20, alpha=0.01):\n",
        "    m.eval(); tot=0; ok=0\n",
        "    for x,y in loader:\n",
        "        if method=='fgsm':\n",
        "            x_adv = fgsm(m, x, y, eps)\n",
        "        else:\n",
        "            x_adv = pgd(m, x, y, eps=eps, alpha=alpha, steps=steps)\n",
        "        with torch.no_grad():\n",
        "            pred = m(x_adv).argmax(1)\n",
        "            ok += (pred.cpu()==y).sum().item(); tot += y.size(0)\n",
        "    return ok/max(1,tot)\n",
        "\n",
        "def targeted_asr_curve(m, loader, eps_list, steps=30, alpha=0.01, num_starts=3):\n",
        "    # Attack success rate vs ε using targeted PGD with multiple random starts\n",
        "    m.eval()\n",
        "    results = []\n",
        "    for eps in eps_list:\n",
        "        tot = 0; success = 0\n",
        "        for x,y in loader:\n",
        "            x0 = x.to(device)\n",
        "            t  = ((y + 1) % 10).to(device)\n",
        "            # Track success per-sample across starts\n",
        "            success_mask = torch.zeros(x0.size(0), dtype=torch.bool, device=device)\n",
        "            for s in range(num_starts):\n",
        "                x_adv = (x0 + torch.empty_like(x0).uniform_(-eps, eps)).clamp(-1,1)\n",
        "                for _ in range(steps):\n",
        "                    x_adv.requires_grad_(True)\n",
        "                    logits = m(x_adv)\n",
        "                    loss = ce(logits, t)\n",
        "                    grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "                    with torch.no_grad():\n",
        "                        x_adv = x_adv - alpha * grad.sign()\n",
        "                        x_adv = torch.min(torch.max(x_adv, x0 - eps), x0 + eps)\n",
        "                        x_adv.clamp_(-1, 1)\n",
        "                with torch.no_grad():\n",
        "                    pred = m(x_adv).argmax(1)\n",
        "                    success_mask |= (pred == t)\n",
        "            success += success_mask.sum().item(); tot += x0.size(0)\n",
        "        results.append(success / max(1, tot))\n",
        "    return results\n",
        "\n",
        "# Evaluate\n",
        "eps_list = [0.0, 0.01, 0.02, 0.03, 0.05]\n",
        "fgsm_curve = []\n",
        "pgd_curve  = []\n",
        "for e in eps_list:\n",
        "    if e == 0.0:\n",
        "        fgsm_curve.append(acc_clean(model, subset_loader))\n",
        "        pgd_curve.append(acc_clean(model, subset_loader))\n",
        "    else:\n",
        "        fgsm_curve.append(acc_under_attack(model, subset_loader, method='fgsm', eps=e))\n",
        "        pgd_curve.append(acc_under_attack(model, subset_loader, method='pgd', eps=e, steps=20, alpha=0.01))\n",
        "\n",
        "# Targeted ASR across ε (omit 0.0)\n",
        "asr_eps = [0.01, 0.02, 0.03, 0.05]\n",
        "asr_curve = targeted_asr_curve(model, subset_loader, eps_list=asr_eps, steps=30, alpha=0.01, num_starts=3)\n",
        "\n",
        "print('FGSM acc:', [f\"{v:.4f}\" for v in fgsm_curve])\n",
        "print('PGD  acc:', [f\"{v:.4f}\" for v in pgd_curve])\n",
        "print('Targeted ASR:', dict(zip(asr_eps, [f\"{v:.4f}\" for v in asr_curve])))\n",
        "\n",
        "# Plots\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(eps_list, fgsm_curve, marker='o', label='FGSM')\n",
        "plt.plot(eps_list, pgd_curve, marker='o', label='PGD')\n",
        "plt.ylim(0,1.0)\n",
        "plt.xlabel('ε (L∞)'); plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs ε (FGSM vs PGD)')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "x = list(range(len(asr_eps)))\n",
        "plt.bar(x, asr_curve, width=0.6)\n",
        "plt.xticks(x, [f'ε={e:.02f}' for e in asr_eps])\n",
        "ylim_top = max(0.05, max(asr_curve)*1.25)\n",
        "plt.ylim(0, ylim_top)\n",
        "for i,v in enumerate(asr_curve):\n",
        "    plt.text(i, v + 0.01*ylim_top, f'{v*100:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "plt.title('Targeted Attack Success Rate vs ε (PGD, multi-start)')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S1HDcTOFTNu"
      },
      "source": [
        "\n",
        "## Submission\n",
        "\n",
        "Make sure you have run all cells in your notebook in order before you zip together your submission, so that all images/graphs appear in the output.\n",
        "\n",
        "Please submit a pdf file alongside with the notebook, in colab, you can use \"File -> Print (Ctrl+P)\".\n",
        "\n",
        "For part (b), your submission should consist of two files: this notebook and the saved weights from question 3. There is no need to upload the new, retrained, weights.\n",
        "\n",
        "Please do not run the training loop in gradescope submission.\n",
        "\n",
        "**Please save before exporting!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqsXk4h1Nosk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
